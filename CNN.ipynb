{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be087d1b-3240-466e-9360-bf7200ea4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import wget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79807597-10fd-4dcc-a050-bde070bfd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(\"tmp/Pistachio\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb8af10-6615-4866-9bf7-76dcde62e9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kirmizi_Pistachio', 'Siirt_Pistachio']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07412b7e-e6f5-4a64-9df5-2c231984abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    files = [file for file in os.listdir(folder)]\n",
    "    output = dict()\n",
    "    \n",
    "    for file in files:\n",
    "        print(folder + \"/\" + file)\n",
    "        images = []\n",
    "        \n",
    "        for filename in os.listdir(folder + \"/\" + file):\n",
    "            img = cv2.imread(os.path.join(folder + \"/\" + file, filename))\n",
    "            img = cv2.resize(img, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        output[file] = (np.array(images) / 255).reshape([-1, 64, 64, 1])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5af42f0-8cb4-4dff-bf15-f347edf0b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"tmp/Pistachio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390d4767-4ae6-486c-8a25-c9b0c787be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/Pistachio/Kirmizi_Pistachio\n",
      "tmp/Pistachio/Siirt_Pistachio\n"
     ]
    }
   ],
   "source": [
    "dataset = load_images_from_folder(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df492157-8bb2-4cc3-a327-4a21b7c2a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84705882])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[list(dataset.keys())[0]][0][32][32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff90bcf6-c832-4b77-9829-1e3e6a0ba068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 64, 64, 1)\n",
      "(2148, 1)\n"
     ]
    }
   ],
   "source": [
    "features = dataset[list(dataset.keys())[0]]\n",
    "counter = 0\n",
    "labels = np.full((dataset[list(dataset.keys())[0]].shape[0], 1), counter)\n",
    "for x in list(dataset.keys())[1:]:\n",
    "    counter += 1\n",
    "    features = np.concatenate((features, dataset[x]), axis=0)\n",
    "    labels = np.concatenate((labels, np.full((dataset[x].shape[0], 1), counter)))\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce64e1a-8da0-418a-81b0-177a9cb52954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99ca939c-ece8-4da6-a48f-e20ac1384b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1f2169-8d76-4e45-baa2-1fb98b8ab670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAI/CAYAAABwLA0cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApDElEQVR4nO3dfbDmZ3kf9u99XnfPvmh3tdJKSAIJEMjCDW+CQO06MQoExwSY1kOdcR1Nhg6Txmmc1p0Ue6bNJBNP7WnHmD8SZlTjRJ1iY4bEBTupHSxwCXGQES82LzIGhAQSK61Wq9W+nve7f+xDI7bLfR/tOauj1f35zOzseZ7rt9dzP/c5z5nv8zu/vU6ptQYAYDRT270AAIDtIAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwpJnN/ONSypuTvDfJdJJfq7X+Uuv4uTJfd2TXZh4SAGDDFnM6y3WpXKhWLnZOUCllOsmfJ3ljkoeSfCbJ36i1fuX7/Zu95UD9i+X2i3o8AICn6556d07UYxcMQZv5cdhrk3y91np/rXU5yQeTvG0T/QAAnjGbCUHXJfn2U24/NLkPAOBZb1PXBG1EKeVdSd6VJDuycKkfDgBgQzZzJujhJDc85fb1k/u+R631zlrrbbXW22Yzv4mHAwDYOpsJQZ9JcnMp5aZSylySn0zy0a1ZFgDApXXRPw6rta6WUv5ukt/Puf8i/+u11i9v2coAAC6hTV0TVGv9N0n+zRatBQDgGWNiNAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADGlmuxcAXKRS+sfUenms49nyXIChOBMEAAxJCAIAhiQEAQBDEoIAgCEJQQDAkIQgAGBIQhAAMCRzgmAblNm57jFH/utXN+v1zU90e+yYW2nW19b774MOLpxu1h85uafbY//C2WZ9vfbnBNX3XN2s7/x/vtLtsX52sfMg690e5hXBc4czQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCF1hyWWUn49yVuSHKm1/uDkvgNJfivJjUkeSPKOWmt/chuQJPnq+/5C95gfe/nnm/V9M2e6Pe4/c7C9jqPtAYRJcvTMrmb9yl39deycaQ9t3Igf/MV7mvXff+iWbo/jT7afy0v/7v3dHmvHn+weA1weNnIm6F8kefN59707yd211puT3D25DQBw2eiGoFrrJ5McO+/utyW5a/LxXUnevrXLAgC4tC72mqBDtdbDk48fSXJoi9YDAPCM2PSF0bXWmuT7/kbBUsq7Sin3llLuXcnSZh8OAGBLXGwIerSUcm2STP4+8v0OrLXeWWu9rdZ622zmL/LhAAC21sWGoI8muWPy8R1JPrI1ywEAeGZ0Q1Ap5TeT/IckLy2lPFRKeWeSX0ryxlLK15L8lcltAIDLRjl3Sc8zY285UP9iuf0ZezzYNqU0y/s/tb/b4qW7H23WF9dnuz2OLbfn4pxd6/c4fGZvsz4/vdrtsXu2fT3gieUd3R4v2H3+f1L9Xjun+7OI/uiRm5r1tfX25y1JrvqJB5v1uuTaR3g2uafenRP12AVf3CZGAwBDEoIAgCEJQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhjSz3QuA56LZT1zTrO+aPtntsXt6cdPruGqu/ThfP31Vt8ehne0eU6U/cHV+qj1QcdfMcrfH40vtwY9XzPb36z+58nCzfvhsezBkkpz93fbndu6vPtTtkfW1/jHAJedMEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQzAmCS+D5u55o1mdKf07MqbUdzfpa7b+H2T97ulk/OL/Q7TGV9hygXTNL3R47plaa9ceXd3d7LK21v13NT7dnESXJzqn+PKKefbNnmvXP/f4N3R5zb3xw0+sANs+ZIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJAMS4TzldIsT+/b122xc+rJZn3vzGK3R2/A4OL6bLfHemeg4r6Z9uC/JDmxurNZv2L6bLfHmfW5Zv3KuVPdHj3znf1Kkt2dwY5TpT0Y8tzjtIcyvmzfI90e37zuec366sPf6fYANs+ZIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhmRMET9OJ21/SPWZp/QvN+rVz/VkyS505QC+YO9rt8djq3mZ993x/XtFWuH7uWLN+Zn2+2+PUVPuYndP9OUELU8vN+mPLe/o9pts9XrzwaLfHAx840D7gDdPdHllf6x8DNDkTBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkIQgAGJJhiXC+Wpvlq//e/d0W81PtwX1HV/pD+f7S7vua9YdX93d7TJX1Zn299t8HrXXeK63UDQz265gt/cF/V8+dbNaPruzewOO0B1DumznT7bHW2bMnVnd1e7xm/4PN+r/+nZd1e+x/y9fbB3S+jgFnggCAQQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGZE4QPE375852j9k9s9SsP7G60O3xByd/sFk/NPtkt0dv/s6u6f5cnKOr7fk7G5kTdHJ9R7O+o6x2e/Sey8HZU90ePS/e8Wj3mI8/8QPN+r7Z/p4urbfnFZ1dbteT5KpDVzfrq4/0nwuMzpkgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCEJQQDAkAxLhPNM77uiWZ+fbg9CTJL5zvC/V+/5ZrfH58/c2KwfmOkPB3xsdW+z/uDSwW6P/TOnm/U9U4vdHr1hiXum+wMol2v729WptfZjJMnu6fZap7Pe7bFzeqVZf3SpvedJMjvVHvx43RX9QZhf+Sc3NOsv/duPd3vU1f6QSngucyYIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEjmBMF51p480axfNbfc7TFd+vNmel4wf7RZ//LZ67s9rp09vul1bIWFqf6e9Sytzzbr81Pt+T1JsmuqPeNp3/SZbo+r5k4268dXdnZ7PLG00KzvnevPXtp7sD2/CehzJggAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADCk7rDEUsoNSf6PJIeS1CR31lrfW0o5kOS3ktyY5IEk76i1PnHplgrPjDI316zPl/5AvYeX9jXra7X//mN2arWzjnY9SaZKbdafN9d/yR5faw/2W9vAe6nptIdH7ij9QYdrU+3HWanT3R49+6b6n9tPHX1Rs37z3se6PXZOt5/v3pmz3R4Hr2sPS/y9X3l1t8fNf++e7jHwXLaRM0GrSX6u1nprktcl+ZlSyq1J3p3k7lrrzUnuntwGALgsdENQrfVwrfVzk49PJrkvyXVJ3pbkrslhdyV5+yVaIwDAlnta1wSVUm5M8sok9yQ5VGs9PCk9knM/LgMAuCxsOASVUnYn+ZdJ/n6t9Xt+w2Sttebc9UIX+nfvKqXcW0q5dyXtX14IAPBM2VAIKqXM5lwA+kCt9V9N7n60lHLtpH5tkiMX+re11jtrrbfVWm+bzfxWrBkAYNO6IaiUUpK8P8l9tdZfeUrpo0numHx8R5KPbP3yAAAuje5/kU/yQ0l+OskXSylfmNz3C0l+KcmHSinvTPJgkndckhUCAFwC3RBUa/1UkvJ9yrdv7XJg+9Xl5Wb9ybWd3R57Zxab9R1T/bk4B2ZONeuL67PdHkudY+am+7OGNvsYSTK7gZlGm3Xrjoe7x/TmFT2ydkW3x/2HDzbrR0/t6va47ZpvN+sbmb30C4f+oFn/2MFbuj3KfPsShbrkOk6e20yMBgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADGkjE6NhKIf/u9c36z+180PdHn++eG2zvvZ954/+R4+t7mnW90y1BzImyWJtv8RnNzDocKVON+v7Zk52eyxMtYfuXTndHgyZJAvr7cF+c1nbwDraQypvnb3gr0D8Hv/lyz7brD+6tLfbY3aqvdYji+3PfZJ86uwNzfqe3We7PaY6wxLXOoNDkyT1gr87Gy4LzgQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADMmcIDjPC9/2jWb96Gp/DszZtfb8nYOz/Zk2Z9baM1zOpF1Pkum0Z7js6MzNSZKVzqyhk2s7uz3W6ubfb71o9rFN91jszDz62mq7niQf/HftOVK/89Zf7fb4/VMva9YX5/vzm371G7c361fv7s9euu9/fWmz/pK/fW+3B1zOnAkCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkIQgAGJIQBAAMybBEOM/Ne44061Nlvdvjxh2PN+sPLe/v9ugNMtyR/qDDk2s7mvXd04vdHoudYYmnOo+RJK9caO/HRpxcbz/O82ZOdnvcv3KgWV+YWur2OPCn7feO1//n3Ra57/S1zfpNO492e/wXz/98s76y3v/2/vXP39CsT+3sD8JcP3Omeww8WzkTBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkc4LgPAdnTzXrZ9bmuz3+6p4vNut3nf2hbo8rps8268dWd3V7LEwtN+tL67PdHr05QCvr090ep9fbe3bldHvPk/58puPrc90eV023ZwmtpXR7nHxBu/6PH+1/br96/Opm/WW7H+72WKntfX9oaQOzqG5q74cZQDzXORMEAAxJCAIAhiQEAQBDEoIAgCEJQQDAkIQgAGBIQhAAMCQhCAAYkmGJcJ6jK7ub9f0z/QFyL5hZadavnD3d7dEbhrdnerHb40xngOCebofkZTsfatY/e/qmbo/ec9mI42sLzfreqf5+LEwtNeufO3tjt8faC9uP85mjnWmKSa7ffbxZ38hAznuPP79Zf/kV/YGLO+faX6fwXOdMEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQzAmC8/TmAG1k5s3/eeJlzfrSev+l97rdX2/WH1y+qtujZyPP5dhqe27S8+cf7/bYN93e0xPrO7o9Ftdnm/XeHKEkuWX+cLPemyOUJPlOe61//eV/2m3x7x9/cfshlvZ1e1yz82Szft+pa7o9njzVfi6rf+c/7fa4+p/9UfcYeLZyJggAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkwxLhPN88e7BZv37HE90eS53BfrNTa90eXzp7Q7O+MN0f7HdsdVezPp31bo+r59rH9J5rkhwpe5v1HWW52+PKmVPN+p6pxW6Pazp7dvOub3V7/G83H2/Wr5ppDzFMkoWZ/vPt2TPTfr5Tqd0eb3rRV5v1T3/sVU9rTXC5cSYIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEjmBMF59s6cbdYPzvbnwOwoK836Q8sHuj2WavvleWZlrttjYWrz82jOrM1vukdvltCTdWe3x97p/hygnrXO6Jz9MwvdHov37WvWb335w90ex/e1H+fTx1/Y7bFv9kyzftVc/+v0q6cONesnXtRtkSv7h8CzljNBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIXWHJZZSdiT5ZJL5yfEfrrX+w1LKTUk+mHOzsj6b5KdrrZufzAbbbK3z3uDoyp5uj2vnjjfrK3W622Npvf3ynJ9a7fbY0xkwOFvWuj3WUpr13mDIjTzOntIeUJkky50928g6jq13BkyunOr2uOJr7fpHn3xVt0dviOVrr3ig2+Pk2o5m/aU7Dnd7PLS4v1lf3b3e7QGXs42cCVpK8oZa68uTvCLJm0spr0vyy0neU2t9cZInkrzzkq0SAGCLdUNQPee7b49mJ39qkjck+fDk/ruSvP1SLBAA4FLY0DVBpZTpUsoXkhxJ8rEk30hyvNb63fPxDyW57pKsEADgEthQCKq1rtVaX5Hk+iSvTXLLRh+glPKuUsq9pZR7V7J0casEANhiT+t/h9Vajyf5RJLXJ9lXSvnulZvXJ7ngr06utd5Za72t1nrbbDb/26gBALZCNwSVUq4qpeybfLwzyRuT3JdzYegnJofdkeQjl2iNAABbrvtf5JNcm+SuUsp0zoWmD9Vaf7eU8pUkHyyl/JMkn0/y/ku4TgCALdUNQbXWP03yygvcf3/OXR8Ezym3LnynWV+v7bk5SXL7wp836+85dXu3x96Z9uyc6bL5GS69WTNJf6bRynT/Wr89U715Rf2ZR1dPn+we03Nyvf18d2xgbtITL6vN+t2HX9Lt8eqDDzXrL9z5WLfHD+y84BUI/597Tr6o26OnzpsTxHObidEAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhbWRiNAxlaX22We8ND0ySzyze0Kw/b/54t8eOqZVm/eGlfd0ea3Xz73MWppab9QPTp7s9es9l19Tmf7nyXPqD/Y7V9uf2ltn+7zcsK+1hmY995apuj6v+yn3N+uHlK7o91tJex6NLe7s9Dsy1P3cLB890e8DlzJkgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCGZEwTn6c1fObqyu9ujN0voipn+/JWjK3ua9Z3T7dk7SbK03n6Jb2TmUW9O0Jn1/myd2bK6qXqSTJX+HKCem2cfb9bP1v63xKnOUld2126P9c7X2Om1/p5+82x7HtF1O493e/Q+tysr/a8PuJw5EwQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSYYlwnj85eUOzfvPCkW6Ptbr59xezZa1Z7w1CTJL5zmS//VP9oY0L00vt+lS7niRXz5xs1nsDKpNkcX22Wd+xgeGRJzs9XjTbH1I4fba91uWD/WGJB2dONevfOnug26M3LPPgbHvPk+TPTl3brK+c7O8HXM6cCQIAhiQEAQBDEoIAgCEJQQDAkIQgAGBIQhAAMCQhCAAYkjlBcJ4nlhaa9T17Frs9zqzPNetHVvZ2e/RmDU2V/jya3qyh2c4coSTZUdrzaK6aOdHt8cDywWb9xrmj3R77ptszjeay3u2x3Hnf9+Xls/0e+9uPs+ub/W+r33jNVc36VPqf294xjyxd0e3RmzVV5ttfP3C5cyYIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJMMS4TyPnN7TrB/dt7vb4+DMqU2vozfo8NENDFxcmFre9DoW62yz/vWla7o9Ds0+2azvmeoPKTy21t73hamlbo9dpb0f//7si7o9Utrl9fZ2JUl2T7fXuro+3e1xbLk91HPfXH9P12vnycBznDNBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMyJwjOc/ZjVzfrZ376G90e83MrzfpGZtqs1PasmGvnjnd77CjtdfRmAG3EgQ3MROrNATq5vrPbo/dcejOAkmSxtr/l7d3AvKK1Pe35TYs7arfHFTNnmvVjK7u6PXbNtJ/v2gZmAN3/5JXtA56Y6/aAy5kzQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCEZlgjnufaffbZZX/qp/svm8PK+Zv3AzOmns6QLWpjqDwfc0RkgeGCqP+iwN6Twxtlj3R7H1ha6x/Scru3BfXuy2O3xws6Qwv/7xMu7Pcpi+73j/LH2kMskeen84Wb9yPLebo+vnWkP9dw9u4GBnGud98FT/cGPcDlzJggAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSOYEwXmm5ueb9S8f39ftcduV32ofsNpfx57p9tybqbre7TFX2u9zejOAzvVYa9ZPrrfn9yTJbGk/4bUNvB/blfbMo5Xan88zXUqz/qUnn9ftMbXUXuv6TH+2zmKdbdaX1vvfmldrex29epKsrLX3bPqM98k8t/kKBwCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADGnDwxJLKdNJ7k3ycK31LaWUm5J8MMmVST6b5Kdrre1pZnAZWDtxolmf/8n2oLskefij+5r1Gxce7/Z4dGVvs74w1X+5LU2317owtdTt8bK5I836I2sL3R694YDT6Q8YfN7MyU33WOsc8vxdx7o97lt+YbNe1toDGTfiq08e6h5zxfzZZn3ndH8Q5tJS+/NS+lsKl7WncyboZ5Pc95Tbv5zkPbXWFyd5Isk7t3JhAACX0oZCUCnl+iQ/nuTXJrdLkjck+fDkkLuSvP0SrA8A4JLY6JmgX03yD5J895cVXZnkeK31u78Q6KEk123t0gAALp1uCCqlvCXJkVrrZy/mAUop7yql3FtKuXcl/esPAACeCRu5MPqHkry1lPLXkuxIsjfJe5PsK6XMTM4GXZ/k4Qv941rrnUnuTJK95YDL7ACAZ4XumaBa68/XWq+vtd6Y5CeTfLzW+lNJPpHkJyaH3ZHkI5dslQAAW2wzc4L+xyT/fSnl6zl3jdD7t2ZJAACX3obnBCVJrfUPk/zh5OP7k7x265cE26y057ysHe3P+Jmd2tOsH1/pz9ZZT3sdvTkxSTJV1pv1HaU/S+bbq+15RUfW2s81Sa6cPtWs99aZJCu1/Z7tO2u7uj1unWvPGvr9b/xAt0dZa9d3Ptptkb1Ti8369FR/P3qW1vrf3qem2lcorMy6goHnNhOjAYAhCUEAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQ3pawxJhCHXzA+K+c/qKZv35u5/o9liv7WGJp9bmuz1W6nSzfmam32OxznYeo/9t5GtL1zTrr9r5QLfH8fX2WnvrTJLvrLbXuusP+wMXFw+2Py8nb+p//RzoDI9cWW9/3pJk18xys356da7bY+l0+5jZM+3nCpc7Z4IAgCEJQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhmROEDxdZQOzU25/qFle//TubovDZ/c263tmF7s9dk8vNevfXjnQ7bGjrDbrN8w93u0x2+nx2Nqebo+ea6ZPdI9Z7Mw0Wtrf/9wuHlpr1nd/sz/j5+T6jmb9yMn+10dvTtBG1PX2873mj9vPFS53zgQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGZFgiPF21brrFFx+/tnvM9XuON+vfOXtFt8cDp65s1g/t7A8Y3DvTHsrYG4SYJNfMPtmsP7baHgyZJDfOHm3W9031hwd+cfmaZn1lT/9zu/Ph9jDEDWxHptN+nIO7T3d7LK61v30fPtHf0yy33wfv+J0/7veAy5gzQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDMicItsH+H/9a95hrPrOjWT+yuHvT6zi9Ot895qq5U836t5bas4iSZLHOth9j5mS3x1pK5zHa83uS5PNnXtCsl/Vui/Qe5vTz+02umm7PAXr4WH8G1P49Z5r1s2fnuj1mnuzvGTyXORMEAAxJCAIAhiQEAQBDEoIAgCEJQQDAkIQgAGBIQhAAMCQhCAAYkmGJsB1Ke/Bfktx3/FCzftuV3+r2OLHaHri4vN7/FrAwtdysH5hpD1PcKrtKZx1Ta90eH/rzVzXrU0v9z8t0exkbslLb7z+Xz7aHSybJ8bLQfowN9Jj2NpjBeQkAAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADMmcINgOtXYPmf+xh5v1pU/3X777Zs+2e2xgTtB0WW/WV2q/x1ra83fW1jbwfqwz9ubba/PdFjP37GnWp374iW6P5S/sbx/Q/9TmiqmVdouz/T1dnW1/XqaP9Xu8+Oc/015HtwNc3pwJAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADMmwRHiWqqurzfqf/k+v6fZ40y9/sll/oi50e5xc29Gsr9X+e6lDs08263um20Mdk2SqM7TxnjMv7vY4fUO7x+xSZyJjkr3fao8QfPJNZ7o97lm8oX3AdH9M4erxuWb9lv/5T7s91jtfY/Bc50wQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJDMCYLL1I4/+JPuMR979JZm/aqdp7o9XrL7SLN+cPZkt8euqaVN1ZPk/uWrm/X3/caPd3tM3dqeRzTzhd39HivtGT7ve80Huj0+d/bGZn36xHS3x4vf/blmfX1ludsDRudMEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEgbGpZYSnkgyckka0lWa623lVIOJPmtJDcmeSDJO2qtT1yaZQLnqxsYhvfoJ69r1p98zePdHotrs8368YWFbo/X7/1695ieDx95dbO+ePV6t8ctz3u0WT/x2zd0ezxxc3uQ4TXT/QGUn3jspc36i37u090e7ZGNwEY8nTNBP1prfUWt9bbJ7XcnubvWenOSuye3AQAuC5v5cdjbktw1+fiuJG/f9GoAAJ4hGw1BNcm/LaV8tpTyrsl9h2qthycfP5Lk0JavDgDgEtnoL1D94Vrrw6WUq5N8rJTyZ08t1lprKeWCP6KehKZ3JcmO9K8dAAB4JmzoTFCt9eHJ30eS/HaS1yZ5tJRybZJM/r7gr5qutd5Za72t1nrbbOa3ZtUAAJvUDUGllF2llD3f/TjJm5J8KclHk9wxOeyOJB+5VIsEANhqG/lx2KEkv11K+e7xv1Fr/b1SymeSfKiU8s4kDyZ5x6VbJgDA1uqGoFrr/UlefoH7H09y+6VYFLA1nv+//HGzvvJ7z+v2ePjE3mb9+oXj3R6zZbVZ//byld0eJ3+kPdOo/u83dns88PH2MWuv6E/fufmHv9msL9b2HKEkWfvR73SPAS49E6MBgCEJQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBD2ugvUAUuQ3W1PaRw7i0X/JV/32Pv7xxq1qfSHzD42Gp74OIH/tGP99cxfW+z/uKbHu32OHygvY79C2e7Pf7m8/6oWf+NY6/r9kjWN3AMcKk5EwQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJHOCYGDri4vdYxb+5lKz/o0T/W8jXzt7dbO+Z/3T3R69aUQzbz3W7fHWTz3YrP+Hozd1e+ybOtOsf/zX+3OCrk571hDwzHAmCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCEJQQDAkIQgAGBIQhAAMCTDEoGm1cOPbPcSNqb2xikmv/np9iDDv/Of3d3t8clTtzTrV/9TgxDhcuFMEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQzAkCnhPWz5zpHvOS/+aPm/U/KHu3YCX9eUXAs4MzQQDAkIQgAGBIQhAAMCQhCAAYkhAEAAxJCAIAhiQEAQBDEoIAgCEZlgjwXdWgQxiJM0EAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJCEIABgSEIQADAkIQgAGJIQBAAMSQgCAIYkBAEAQxKCAIAhCUEAwJA2FIJKKftKKR8upfxZKeW+UsrrSykHSikfK6V8bfL3/ku9WACArbLRM0HvTfJ7tdZbkrw8yX1J3p3k7lrrzUnuntwGALgsdENQKeWKJD+S5P1JUmtdrrUeT/K2JHdNDrsrydsvzRIBALbeRs4E3ZTksST/vJTy+VLKr5VSdiU5VGs9PDnmkSSHLtUiAQC22kZC0EySVyV5X631lUlO57wffdVaa5J6oX9cSnlXKeXeUsq9K1na7HoBALbERkLQQ0keqrXeM7n94ZwLRY+WUq5NksnfRy70j2utd9Zab6u13jab+a1YMwDApnVDUK31kSTfLqW8dHLX7Um+kuSjSe6Y3HdHko9ckhUCAFwCMxs87r9N8oFSylyS+5P8rZwLUB8qpbwzyYNJ3nFplggAsPU2FIJqrV9IctsFSrdv6WoAAJ4hJkYDAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCGJAQBAEMqtdZn7sFKeSzJg0+562CSo8/YAsZgT7eePd169nTr2dOtZ0+33nbs6QtqrVddqPCMhqD/34OXcm+t9bZtW8BzkD3devZ069nTrWdPt5493XrPtj314zAAYEhCEAAwpO0OQXdu8+M/F9nTrWdPt5493Xr2dOvZ0633rNrTbb0mCABgu2z3mSAAgG2xbSGolPLmUspXSylfL6W8e7vWcTkrpfx6KeVIKeVLT7nvQCnlY6WUr03+3r+da7yclFJuKKV8opTylVLKl0spPzu5355epFLKjlLKH5dS/mSyp/9ocv9NpZR7Jq//3yqlzG33Wi83pZTpUsrnSym/O7ltTzehlPJAKeWLpZQvlFLundzntb8JpZR9pZQPl1L+rJRyXynl9c+2Pd2WEFRKmU7yT5P8WJJbk/yNUsqt27GWy9y/SPLm8+57d5K7a603J7l7cpuNWU3yc7XWW5O8LsnPTL4u7enFW0ryhlrry5O8IsmbSymvS/LLSd5Ta31xkieSvHP7lnjZ+tkk9z3ltj3dvB+ttb7iKf+F22t/c96b5PdqrbckeXnOfb0+q/Z0u84EvTbJ12ut99dal5N8MMnbtmktl61a6yeTHDvv7rcluWvy8V1J3v5MrulyVms9XGv93OTjkzn3gr0u9vSi1XNOTW7OTv7UJG9I8uHJ/fb0aSqlXJ/kx5P82uR2iT29FLz2L1Ip5YokP5Lk/UlSa12utR7Ps2xPtysEXZfk20+5/dDkPjbvUK318OTjR5Ic2s7FXK5KKTcmeWWSe2JPN2XyY5svJDmS5GNJvpHkeK11dXKI1//T96tJ/kGS9cntK2NPN6sm+bellM+WUt41uc9r/+LdlOSxJP988mPbXyul7MqzbE9dGP0cVs/91z///e9pKqXsTvIvk/z9WuuJp9bs6dNXa12rtb4iyfU5dxb4lu1d0eWtlPKWJEdqrZ/d7rU8x/xwrfVVOXeZxs+UUn7kqUWv/adtJsmrkryv1vrKJKdz3o++ng17ul0h6OEkNzzl9vWT+9i8R0sp1ybJ5O8j27yey0opZTbnAtAHaq3/anK3Pd0Ck1Phn0jy+iT7Sikzk5LX/9PzQ0neWkp5IOcuJXhDzl17YU83odb68OTvI0l+O+cCu9f+xXsoyUO11nsmtz+cc6HoWbWn2xWCPpPk5sn/ZphL8pNJPrpNa3mu+WiSOyYf35HkI9u4lsvK5LqK9ye5r9b6K08p2dOLVEq5qpSyb/LxziRvzLlrrT6R5Ccmh9nTp6HW+vO11utrrTfm3PfOj9dafyr29KKVUnaVUvZ89+Mkb0rypXjtX7Ra6yNJvl1KeenkrtuTfCXPsj3dtmGJpZS/lnM/155O8uu11l/cloVcxkopv5nkL+fcb+V9NMk/TPJ/JflQkucneTDJO2qt5188zQWUUn44yb9L8sX8x2stfiHnrguypxehlPIXcu7ix+mce9P1oVrrPy6lvDDnzmIcSPL5JP9VrXVp+1Z6eSql/OUk/0Ot9S329OJN9u63JzdnkvxGrfUXSylXxmv/opVSXpFzF+/PJbk/yd/K5PtAniV7amI0ADAkF0YDAEMSggCAIQlBAMCQhCAAYEhCEAAwJCEIABiSEAQADEkIAgCG9P8CufQuhcBGQE8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.imshow(dataset[list(dataset.keys())[0]][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "127553dd-a26c-4d81-8388-9dcfd75c27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convolutional_model(activation_functions, type_of_pooling, inp_shape, alpha=0.2, num_classes=2):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), activation=activation_functions[\"hidden layer\"], padding='same', input_shape=inp_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), activation=activation_functions[\"hidden layer\"], padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), activation=activation_functions[\"hidden layer\"], padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), activation=activation_functions[\"hidden layer\"], padding='same'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation=activation_functions[\"hidden layer\"]))\n",
    "    model.add(layers.Dropout(alpha))\n",
    "    \n",
    "    if activation_functions[\"output layer\"] == activations.softmax:\n",
    "        model.add(layers.Dense(num_classes, activation=activation_functions[\"output layer\"]))\n",
    "    else:\n",
    "        model.add(layers.Dense(num_classes - 1, activation=activation_functions[\"output layer\"]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbbb8ec0-62d0-437d-b2b7-f81489f47f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "  \"hidden layer\": activations.relu,\n",
    "  \"output layer\": activations.softmax,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f27b7e1-5b36-438c-a258-e7363af10326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 8, 8, 64)          102464    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 2, 2, 128)         204928    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 128)         409728    \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 752,322\n",
      "Trainable params: 752,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_convolutional_model(activation_functions, \"max\", [64, 64, 1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "158d8c11-c861-4797-ad1e-f028a6be060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_adam = tf.keras.optimizers.Adam(learning_rate=0.00025)\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "scc = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=opt_adam, loss=scc, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cda5b9a-f28c-41f7-854f-bde9acbd3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6924 - accuracy: 0.5530 - val_loss: 0.6901 - val_accuracy: 0.5674\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 0.6894 - accuracy: 0.5751 - val_loss: 0.6871 - val_accuracy: 0.5674\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 2s 755ms/step - loss: 0.6863 - accuracy: 0.5751 - val_loss: 0.6832 - val_accuracy: 0.5674\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 2s 764ms/step - loss: 0.6819 - accuracy: 0.5751 - val_loss: 0.6782 - val_accuracy: 0.5674\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 2s 823ms/step - loss: 0.6769 - accuracy: 0.5751 - val_loss: 0.6719 - val_accuracy: 0.5674\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 1s 701ms/step - loss: 0.6697 - accuracy: 0.5751 - val_loss: 0.6638 - val_accuracy: 0.5674\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 2s 811ms/step - loss: 0.6614 - accuracy: 0.5751 - val_loss: 0.6527 - val_accuracy: 0.5698\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 2s 755ms/step - loss: 0.6499 - accuracy: 0.5821 - val_loss: 0.6374 - val_accuracy: 0.6047\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 2s 801ms/step - loss: 0.6346 - accuracy: 0.6112 - val_loss: 0.6169 - val_accuracy: 0.6698\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 2s 675ms/step - loss: 0.6130 - accuracy: 0.6682 - val_loss: 0.5911 - val_accuracy: 0.7023\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 2s 734ms/step - loss: 0.5873 - accuracy: 0.7101 - val_loss: 0.5600 - val_accuracy: 0.7302\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 2s 810ms/step - loss: 0.5584 - accuracy: 0.7480 - val_loss: 0.5250 - val_accuracy: 0.7628\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 2s 715ms/step - loss: 0.5222 - accuracy: 0.7771 - val_loss: 0.4897 - val_accuracy: 0.7860\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 2s 734ms/step - loss: 0.4926 - accuracy: 0.7742 - val_loss: 0.4603 - val_accuracy: 0.7907\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 2s 806ms/step - loss: 0.4650 - accuracy: 0.7858 - val_loss: 0.4415 - val_accuracy: 0.8047\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 2s 732ms/step - loss: 0.4532 - accuracy: 0.7852 - val_loss: 0.4382 - val_accuracy: 0.8047\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 2s 757ms/step - loss: 0.4477 - accuracy: 0.7858 - val_loss: 0.4380 - val_accuracy: 0.8047\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 2s 801ms/step - loss: 0.4494 - accuracy: 0.7881 - val_loss: 0.4286 - val_accuracy: 0.8023\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 2s 721ms/step - loss: 0.4395 - accuracy: 0.7875 - val_loss: 0.4250 - val_accuracy: 0.8093\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 2s 740ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4183 - val_accuracy: 0.8070\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 2s 787ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.4175 - val_accuracy: 0.8023\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.4092 - val_accuracy: 0.8140\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 2s 690ms/step - loss: 0.4082 - accuracy: 0.8050 - val_loss: 0.4074 - val_accuracy: 0.8279\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 2s 770ms/step - loss: 0.4008 - accuracy: 0.8201 - val_loss: 0.4053 - val_accuracy: 0.8233\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 2s 723ms/step - loss: 0.3943 - accuracy: 0.8225 - val_loss: 0.3982 - val_accuracy: 0.8326\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 1s 703ms/step - loss: 0.3845 - accuracy: 0.8260 - val_loss: 0.3964 - val_accuracy: 0.8233\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 0.3773 - accuracy: 0.8324 - val_loss: 0.3928 - val_accuracy: 0.8349\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 2s 801ms/step - loss: 0.3763 - accuracy: 0.8335 - val_loss: 0.3916 - val_accuracy: 0.8349\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 2s 693ms/step - loss: 0.3748 - accuracy: 0.8283 - val_loss: 0.3865 - val_accuracy: 0.8302\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 2s 757ms/step - loss: 0.3647 - accuracy: 0.8382 - val_loss: 0.3897 - val_accuracy: 0.8442\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 2s 809ms/step - loss: 0.3629 - accuracy: 0.8341 - val_loss: 0.3804 - val_accuracy: 0.8279\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 0.3549 - accuracy: 0.8388 - val_loss: 0.3965 - val_accuracy: 0.8349\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 2s 694ms/step - loss: 0.3635 - accuracy: 0.8329 - val_loss: 0.4062 - val_accuracy: 0.7977\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 0.3800 - accuracy: 0.8219 - val_loss: 0.3898 - val_accuracy: 0.8349\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.3549 - accuracy: 0.8417 - val_loss: 0.3807 - val_accuracy: 0.8279\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 0.3511 - accuracy: 0.8417 - val_loss: 0.3757 - val_accuracy: 0.8442\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 1s 719ms/step - loss: 0.3522 - accuracy: 0.8393 - val_loss: 0.3590 - val_accuracy: 0.8512\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 2s 812ms/step - loss: 0.3377 - accuracy: 0.8481 - val_loss: 0.3585 - val_accuracy: 0.8442\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 2s 725ms/step - loss: 0.3345 - accuracy: 0.8510 - val_loss: 0.3556 - val_accuracy: 0.8465\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 2s 777ms/step - loss: 0.3305 - accuracy: 0.8562 - val_loss: 0.3529 - val_accuracy: 0.8465\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 0.3289 - accuracy: 0.8487 - val_loss: 0.3511 - val_accuracy: 0.8488\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 2s 762ms/step - loss: 0.3238 - accuracy: 0.8562 - val_loss: 0.3482 - val_accuracy: 0.8581\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 2s 717ms/step - loss: 0.3256 - accuracy: 0.8539 - val_loss: 0.3483 - val_accuracy: 0.8535\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 0.3189 - accuracy: 0.8609 - val_loss: 0.3431 - val_accuracy: 0.8558\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 2s 762ms/step - loss: 0.3168 - accuracy: 0.8597 - val_loss: 0.3421 - val_accuracy: 0.8535\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 2s 729ms/step - loss: 0.3076 - accuracy: 0.8679 - val_loss: 0.3398 - val_accuracy: 0.8512\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 2s 758ms/step - loss: 0.3114 - accuracy: 0.8638 - val_loss: 0.3406 - val_accuracy: 0.8605\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 2s 798ms/step - loss: 0.3086 - accuracy: 0.8597 - val_loss: 0.3345 - val_accuracy: 0.8558\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 2s 752ms/step - loss: 0.2955 - accuracy: 0.8690 - val_loss: 0.3297 - val_accuracy: 0.8744\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 2s 742ms/step - loss: 0.2965 - accuracy: 0.8685 - val_loss: 0.3355 - val_accuracy: 0.8488\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 2s 789ms/step - loss: 0.3037 - accuracy: 0.8661 - val_loss: 0.3286 - val_accuracy: 0.8605\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 2s 735ms/step - loss: 0.2916 - accuracy: 0.8714 - val_loss: 0.3248 - val_accuracy: 0.8674\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 2s 725ms/step - loss: 0.2915 - accuracy: 0.8714 - val_loss: 0.3396 - val_accuracy: 0.8558\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 2s 802ms/step - loss: 0.3185 - accuracy: 0.8539 - val_loss: 0.3212 - val_accuracy: 0.8744\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 2s 758ms/step - loss: 0.2846 - accuracy: 0.8824 - val_loss: 0.3220 - val_accuracy: 0.8698\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 2s 730ms/step - loss: 0.2913 - accuracy: 0.8661 - val_loss: 0.3344 - val_accuracy: 0.8651\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 1s 747ms/step - loss: 0.2917 - accuracy: 0.8766 - val_loss: 0.3616 - val_accuracy: 0.8279\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 2s 775ms/step - loss: 0.3006 - accuracy: 0.8702 - val_loss: 0.3383 - val_accuracy: 0.8651\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.2941 - accuracy: 0.8778 - val_loss: 0.3605 - val_accuracy: 0.8279\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 1s 707ms/step - loss: 0.3108 - accuracy: 0.8620 - val_loss: 0.3203 - val_accuracy: 0.8721\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 2s 810ms/step - loss: 0.2797 - accuracy: 0.8813 - val_loss: 0.3307 - val_accuracy: 0.8535\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 0.2749 - accuracy: 0.8801 - val_loss: 0.3261 - val_accuracy: 0.8744\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 2s 778ms/step - loss: 0.2828 - accuracy: 0.8847 - val_loss: 0.3329 - val_accuracy: 0.8488\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 2s 798ms/step - loss: 0.2786 - accuracy: 0.8772 - val_loss: 0.3236 - val_accuracy: 0.8791\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 2s 826ms/step - loss: 0.2733 - accuracy: 0.8847 - val_loss: 0.3605 - val_accuracy: 0.8372\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 2s 734ms/step - loss: 0.2914 - accuracy: 0.8714 - val_loss: 0.3644 - val_accuracy: 0.8372\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 2s 822ms/step - loss: 0.3050 - accuracy: 0.8679 - val_loss: 0.3602 - val_accuracy: 0.8372\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 2s 755ms/step - loss: 0.2908 - accuracy: 0.8743 - val_loss: 0.3497 - val_accuracy: 0.8488\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 1s 697ms/step - loss: 0.2961 - accuracy: 0.8766 - val_loss: 0.3432 - val_accuracy: 0.8349\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 2s 748ms/step - loss: 0.2852 - accuracy: 0.8690 - val_loss: 0.3253 - val_accuracy: 0.8721\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 2s 801ms/step - loss: 0.2780 - accuracy: 0.8813 - val_loss: 0.3242 - val_accuracy: 0.8605\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 1s 706ms/step - loss: 0.2779 - accuracy: 0.8783 - val_loss: 0.3137 - val_accuracy: 0.8767\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 2s 761ms/step - loss: 0.2815 - accuracy: 0.8760 - val_loss: 0.3275 - val_accuracy: 0.8605\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 2s 794ms/step - loss: 0.2905 - accuracy: 0.8679 - val_loss: 0.3066 - val_accuracy: 0.8814\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.2761 - accuracy: 0.8813 - val_loss: 0.3067 - val_accuracy: 0.8814\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 2s 714ms/step - loss: 0.2721 - accuracy: 0.8778 - val_loss: 0.3173 - val_accuracy: 0.8628\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 2s 809ms/step - loss: 0.2723 - accuracy: 0.8760 - val_loss: 0.3145 - val_accuracy: 0.8791\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 2s 725ms/step - loss: 0.2668 - accuracy: 0.8813 - val_loss: 0.3233 - val_accuracy: 0.8628\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 1s 695ms/step - loss: 0.2654 - accuracy: 0.8853 - val_loss: 0.3203 - val_accuracy: 0.8767\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 1s 713ms/step - loss: 0.2686 - accuracy: 0.8888 - val_loss: 0.3149 - val_accuracy: 0.8605\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 2s 800ms/step - loss: 0.2617 - accuracy: 0.8912 - val_loss: 0.3023 - val_accuracy: 0.8860\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 2s 779ms/step - loss: 0.2594 - accuracy: 0.8964 - val_loss: 0.3050 - val_accuracy: 0.8721\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 2s 768ms/step - loss: 0.2529 - accuracy: 0.8970 - val_loss: 0.3034 - val_accuracy: 0.8698\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 2s 822ms/step - loss: 0.2538 - accuracy: 0.8941 - val_loss: 0.3011 - val_accuracy: 0.8814\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 2s 740ms/step - loss: 0.2484 - accuracy: 0.8999 - val_loss: 0.3022 - val_accuracy: 0.8721\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 2s 687ms/step - loss: 0.2462 - accuracy: 0.8987 - val_loss: 0.3015 - val_accuracy: 0.8884\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 2s 847ms/step - loss: 0.2506 - accuracy: 0.8929 - val_loss: 0.3130 - val_accuracy: 0.8651\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 2s 760ms/step - loss: 0.2521 - accuracy: 0.8946 - val_loss: 0.3022 - val_accuracy: 0.8860\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 2s 720ms/step - loss: 0.2513 - accuracy: 0.8900 - val_loss: 0.3040 - val_accuracy: 0.8698\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 2s 806ms/step - loss: 0.2460 - accuracy: 0.8970 - val_loss: 0.2964 - val_accuracy: 0.8884\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 2s 785ms/step - loss: 0.2419 - accuracy: 0.9034 - val_loss: 0.2971 - val_accuracy: 0.8814\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 2s 723ms/step - loss: 0.2401 - accuracy: 0.9010 - val_loss: 0.2978 - val_accuracy: 0.8767\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 2s 791ms/step - loss: 0.2406 - accuracy: 0.9010 - val_loss: 0.3014 - val_accuracy: 0.8698\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 2s 775ms/step - loss: 0.2402 - accuracy: 0.9022 - val_loss: 0.2969 - val_accuracy: 0.8930\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 2s 743ms/step - loss: 0.2377 - accuracy: 0.9022 - val_loss: 0.3056 - val_accuracy: 0.8651\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 2s 784ms/step - loss: 0.2369 - accuracy: 0.9034 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 2s 839ms/step - loss: 0.2327 - accuracy: 0.9045 - val_loss: 0.3144 - val_accuracy: 0.8651\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 2s 757ms/step - loss: 0.2410 - accuracy: 0.9010 - val_loss: 0.3046 - val_accuracy: 0.8814\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 2s 707ms/step - loss: 0.2500 - accuracy: 0.8964 - val_loss: 0.2985 - val_accuracy: 0.8767\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 2s 775ms/step - loss: 0.2436 - accuracy: 0.9040 - val_loss: 0.3002 - val_accuracy: 0.8721\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 2s 761ms/step - loss: 0.2406 - accuracy: 0.8987 - val_loss: 0.3114 - val_accuracy: 0.8791\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 1s 689ms/step - loss: 0.2447 - accuracy: 0.8958 - val_loss: 0.3237 - val_accuracy: 0.8698\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 2s 767ms/step - loss: 0.2451 - accuracy: 0.8917 - val_loss: 0.3043 - val_accuracy: 0.8814\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 2s 739ms/step - loss: 0.2346 - accuracy: 0.9028 - val_loss: 0.3233 - val_accuracy: 0.8721\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 2s 689ms/step - loss: 0.2399 - accuracy: 0.8993 - val_loss: 0.3057 - val_accuracy: 0.8814\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 2s 807ms/step - loss: 0.2342 - accuracy: 0.9086 - val_loss: 0.3320 - val_accuracy: 0.8674\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 2s 808ms/step - loss: 0.2468 - accuracy: 0.8929 - val_loss: 0.3063 - val_accuracy: 0.8837\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 2s 731ms/step - loss: 0.2337 - accuracy: 0.9022 - val_loss: 0.3213 - val_accuracy: 0.8744\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 2s 744ms/step - loss: 0.2365 - accuracy: 0.9016 - val_loss: 0.3028 - val_accuracy: 0.8814\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 2s 763ms/step - loss: 0.2277 - accuracy: 0.9034 - val_loss: 0.3227 - val_accuracy: 0.8721\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 2s 728ms/step - loss: 0.2322 - accuracy: 0.8976 - val_loss: 0.3086 - val_accuracy: 0.8791\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 2s 758ms/step - loss: 0.2343 - accuracy: 0.8999 - val_loss: 0.3106 - val_accuracy: 0.8674\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 2s 761ms/step - loss: 0.2265 - accuracy: 0.9040 - val_loss: 0.2976 - val_accuracy: 0.8930\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 2s 805ms/step - loss: 0.2317 - accuracy: 0.9069 - val_loss: 0.2948 - val_accuracy: 0.8814\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 0.2290 - accuracy: 0.9063 - val_loss: 0.2984 - val_accuracy: 0.8721\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 2s 750ms/step - loss: 0.2170 - accuracy: 0.9115 - val_loss: 0.2932 - val_accuracy: 0.8837\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 2s 791ms/step - loss: 0.2126 - accuracy: 0.9144 - val_loss: 0.2928 - val_accuracy: 0.8860\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 2s 735ms/step - loss: 0.2127 - accuracy: 0.9173 - val_loss: 0.2929 - val_accuracy: 0.8837\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 0.2103 - accuracy: 0.9156 - val_loss: 0.2949 - val_accuracy: 0.8791\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 2s 825ms/step - loss: 0.2137 - accuracy: 0.9185 - val_loss: 0.2934 - val_accuracy: 0.8930\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 2s 731ms/step - loss: 0.2123 - accuracy: 0.9173 - val_loss: 0.2917 - val_accuracy: 0.8767\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.2061 - accuracy: 0.9191 - val_loss: 0.2905 - val_accuracy: 0.8791\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 2s 781ms/step - loss: 0.2072 - accuracy: 0.9203 - val_loss: 0.2896 - val_accuracy: 0.8837\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 2s 727ms/step - loss: 0.2057 - accuracy: 0.9197 - val_loss: 0.2939 - val_accuracy: 0.8791\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 2s 786ms/step - loss: 0.2019 - accuracy: 0.9243 - val_loss: 0.2981 - val_accuracy: 0.8860\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 2s 748ms/step - loss: 0.2089 - accuracy: 0.9144 - val_loss: 0.3083 - val_accuracy: 0.8744\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 0.2123 - accuracy: 0.9127 - val_loss: 0.2930 - val_accuracy: 0.8791\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 2s 725ms/step - loss: 0.2038 - accuracy: 0.9208 - val_loss: 0.2927 - val_accuracy: 0.8860\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 2s 771ms/step - loss: 0.2009 - accuracy: 0.9179 - val_loss: 0.2930 - val_accuracy: 0.8860\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 2s 768ms/step - loss: 0.2049 - accuracy: 0.9185 - val_loss: 0.2920 - val_accuracy: 0.8860\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 1s 695ms/step - loss: 0.2019 - accuracy: 0.9173 - val_loss: 0.3329 - val_accuracy: 0.8628\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 2s 735ms/step - loss: 0.2225 - accuracy: 0.9028 - val_loss: 0.2914 - val_accuracy: 0.8860\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 2s 826ms/step - loss: 0.1986 - accuracy: 0.9232 - val_loss: 0.2933 - val_accuracy: 0.8907\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 2s 719ms/step - loss: 0.1940 - accuracy: 0.9237 - val_loss: 0.2968 - val_accuracy: 0.8814\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 2s 751ms/step - loss: 0.1899 - accuracy: 0.9267 - val_loss: 0.2947 - val_accuracy: 0.8907\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 2s 804ms/step - loss: 0.1926 - accuracy: 0.9232 - val_loss: 0.3559 - val_accuracy: 0.8581\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 2s 740ms/step - loss: 0.2085 - accuracy: 0.9162 - val_loss: 0.3993 - val_accuracy: 0.8465\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 2s 739ms/step - loss: 0.3080 - accuracy: 0.8615 - val_loss: 0.3186 - val_accuracy: 0.8721\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 2s 761ms/step - loss: 0.2353 - accuracy: 0.8970 - val_loss: 0.2956 - val_accuracy: 0.8837\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 0.2328 - accuracy: 0.9040 - val_loss: 0.2993 - val_accuracy: 0.8791\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 2s 706ms/step - loss: 0.2166 - accuracy: 0.9127 - val_loss: 0.2983 - val_accuracy: 0.8884\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 2s 757ms/step - loss: 0.2147 - accuracy: 0.9156 - val_loss: 0.3126 - val_accuracy: 0.8721\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 2s 752ms/step - loss: 0.2203 - accuracy: 0.9104 - val_loss: 0.2987 - val_accuracy: 0.8884\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 1s 681ms/step - loss: 0.1971 - accuracy: 0.9191 - val_loss: 0.3200 - val_accuracy: 0.8698\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 1s 692ms/step - loss: 0.1968 - accuracy: 0.9197 - val_loss: 0.3174 - val_accuracy: 0.8837\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 2s 781ms/step - loss: 0.2109 - accuracy: 0.9080 - val_loss: 0.3132 - val_accuracy: 0.8744\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 2s 714ms/step - loss: 0.1933 - accuracy: 0.9226 - val_loss: 0.3039 - val_accuracy: 0.8860\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 2s 835ms/step - loss: 0.1902 - accuracy: 0.9261 - val_loss: 0.3168 - val_accuracy: 0.8698\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 2s 742ms/step - loss: 0.1959 - accuracy: 0.9208 - val_loss: 0.2989 - val_accuracy: 0.8907\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 2s 743ms/step - loss: 0.1908 - accuracy: 0.9237 - val_loss: 0.3053 - val_accuracy: 0.8814\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 0.1860 - accuracy: 0.9325 - val_loss: 0.2979 - val_accuracy: 0.8907\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 1s 699ms/step - loss: 0.1916 - accuracy: 0.9278 - val_loss: 0.3041 - val_accuracy: 0.8860\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 2s 804ms/step - loss: 0.1829 - accuracy: 0.9331 - val_loss: 0.2956 - val_accuracy: 0.8860\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 2s 729ms/step - loss: 0.1845 - accuracy: 0.9377 - val_loss: 0.3068 - val_accuracy: 0.8884\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 2s 705ms/step - loss: 0.1839 - accuracy: 0.9307 - val_loss: 0.2947 - val_accuracy: 0.8860\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 2s 783ms/step - loss: 0.1788 - accuracy: 0.9331 - val_loss: 0.3056 - val_accuracy: 0.8860\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 2s 760ms/step - loss: 0.1829 - accuracy: 0.9278 - val_loss: 0.2919 - val_accuracy: 0.8884\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 2s 803ms/step - loss: 0.1830 - accuracy: 0.9296 - val_loss: 0.2916 - val_accuracy: 0.8791\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 2s 772ms/step - loss: 0.1748 - accuracy: 0.9342 - val_loss: 0.2931 - val_accuracy: 0.8791\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 2s 842ms/step - loss: 0.1750 - accuracy: 0.9371 - val_loss: 0.2932 - val_accuracy: 0.8884\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 2s 791ms/step - loss: 0.1763 - accuracy: 0.9284 - val_loss: 0.3172 - val_accuracy: 0.8791\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 2s 704ms/step - loss: 0.1800 - accuracy: 0.9325 - val_loss: 0.3107 - val_accuracy: 0.8860\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 2s 790ms/step - loss: 0.1876 - accuracy: 0.9267 - val_loss: 0.3041 - val_accuracy: 0.8837\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 2s 796ms/step - loss: 0.1718 - accuracy: 0.9366 - val_loss: 0.2928 - val_accuracy: 0.8860\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 2s 753ms/step - loss: 0.1637 - accuracy: 0.9377 - val_loss: 0.2942 - val_accuracy: 0.8814\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.1629 - accuracy: 0.9441 - val_loss: 0.2910 - val_accuracy: 0.8814\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 2s 815ms/step - loss: 0.1617 - accuracy: 0.9424 - val_loss: 0.2919 - val_accuracy: 0.8814\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 2s 737ms/step - loss: 0.1569 - accuracy: 0.9441 - val_loss: 0.2920 - val_accuracy: 0.8837\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 2s 764ms/step - loss: 0.1586 - accuracy: 0.9412 - val_loss: 0.2949 - val_accuracy: 0.8791\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 2s 787ms/step - loss: 0.1577 - accuracy: 0.9430 - val_loss: 0.2995 - val_accuracy: 0.8884\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 2s 762ms/step - loss: 0.1551 - accuracy: 0.9464 - val_loss: 0.2960 - val_accuracy: 0.8837\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 2s 726ms/step - loss: 0.1644 - accuracy: 0.9389 - val_loss: 0.2930 - val_accuracy: 0.8814\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 2s 752ms/step - loss: 0.1530 - accuracy: 0.9447 - val_loss: 0.2939 - val_accuracy: 0.8814\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 2s 782ms/step - loss: 0.1507 - accuracy: 0.9476 - val_loss: 0.2945 - val_accuracy: 0.8837\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 1s 723ms/step - loss: 0.1540 - accuracy: 0.9453 - val_loss: 0.3228 - val_accuracy: 0.8837\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 2s 751ms/step - loss: 0.1609 - accuracy: 0.9395 - val_loss: 0.3121 - val_accuracy: 0.8814\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 2s 842ms/step - loss: 0.1663 - accuracy: 0.9348 - val_loss: 0.3165 - val_accuracy: 0.8907\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 2s 726ms/step - loss: 0.1567 - accuracy: 0.9400 - val_loss: 0.3011 - val_accuracy: 0.8837\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 2s 764ms/step - loss: 0.1670 - accuracy: 0.9354 - val_loss: 0.2996 - val_accuracy: 0.8860\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 2s 780ms/step - loss: 0.1521 - accuracy: 0.9453 - val_loss: 0.3180 - val_accuracy: 0.8907\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 2s 734ms/step - loss: 0.1539 - accuracy: 0.9430 - val_loss: 0.2969 - val_accuracy: 0.8860\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 2s 709ms/step - loss: 0.1434 - accuracy: 0.9499 - val_loss: 0.3026 - val_accuracy: 0.8884\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 2s 797ms/step - loss: 0.1470 - accuracy: 0.9517 - val_loss: 0.3021 - val_accuracy: 0.8860\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 2s 825ms/step - loss: 0.1430 - accuracy: 0.9494 - val_loss: 0.3176 - val_accuracy: 0.8837\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 2s 712ms/step - loss: 0.1672 - accuracy: 0.9313 - val_loss: 0.3019 - val_accuracy: 0.8884\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 2s 811ms/step - loss: 0.1447 - accuracy: 0.9476 - val_loss: 0.3005 - val_accuracy: 0.8837\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 2s 769ms/step - loss: 0.1400 - accuracy: 0.9511 - val_loss: 0.2954 - val_accuracy: 0.8860\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 1s 657ms/step - loss: 0.1351 - accuracy: 0.9558 - val_loss: 0.2971 - val_accuracy: 0.8884\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 2s 746ms/step - loss: 0.1336 - accuracy: 0.9534 - val_loss: 0.3049 - val_accuracy: 0.8953\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 2s 817ms/step - loss: 0.1359 - accuracy: 0.9534 - val_loss: 0.2999 - val_accuracy: 0.8837\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 1s 691ms/step - loss: 0.1307 - accuracy: 0.9563 - val_loss: 0.3067 - val_accuracy: 0.8884\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 2s 764ms/step - loss: 0.1290 - accuracy: 0.9593 - val_loss: 0.2997 - val_accuracy: 0.8860\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 2s 777ms/step - loss: 0.1344 - accuracy: 0.9569 - val_loss: 0.2980 - val_accuracy: 0.8884\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 2s 747ms/step - loss: 0.1292 - accuracy: 0.9575 - val_loss: 0.3018 - val_accuracy: 0.8907\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 2s 753ms/step - loss: 0.1289 - accuracy: 0.9540 - val_loss: 0.3013 - val_accuracy: 0.8860\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 2s 789ms/step - loss: 0.1277 - accuracy: 0.9587 - val_loss: 0.3019 - val_accuracy: 0.8884\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.1254 - accuracy: 0.9627 - val_loss: 0.3015 - val_accuracy: 0.8837\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 2s 680ms/step - loss: 0.1321 - accuracy: 0.9569 - val_loss: 0.2991 - val_accuracy: 0.8837\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 2s 779ms/step - loss: 0.1248 - accuracy: 0.9575 - val_loss: 0.3197 - val_accuracy: 0.8884\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 2s 765ms/step - loss: 0.1307 - accuracy: 0.9517 - val_loss: 0.2999 - val_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2442d863700>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052b485-4673-48a4-bff5-8f9c7eb1dd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
